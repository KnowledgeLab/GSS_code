{
 "metadata": {
  "name": "",
  "signature": "sha256:cc3ea2f7c45d5c22abca106e193acbcdc6ae6010db9b35a1f818eaa690ecce0b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Sep 09, 2013\n",
      "\n",
      "@author: Misha Teplitskiy\n",
      "\n",
      "filename: create_articleClasses.py\n",
      "\n",
      "description: \n",
      " - This script constructs a list of articleClass instances, where each articleClass contains an article's metadata\n",
      " - the filtering of the articles is done mostly by filterArticleClasses.py,\n",
      " - But I do make the following filters/selections here:\n",
      "   \n",
      "     1. gss_central_variable field must be == 'Yes'\n",
      "     2. no information on GSS years used in the article\n",
      "     3. make sure the stated GSS years the article used actually contain the variables\n",
      "         the article allegedly used\n",
      "\n",
      "- the other filter criteria are performed by filterArticleClasses.py    \n",
      " \n",
      " \n",
      "inputs:\n",
      "\n",
      "outputs:\n",
      " - articleClasses.pickle -- this is a list of articleClass instances\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "# IMPORTS #############################\n",
      "# add GSS Project/Code directory to module search path, just in case\n",
      "import sys\n",
      "sys.path.append('c:/users/misha/dropbox/gss project/gss_code/')\n",
      "sys.path.append('c:/users/dj ukrainium/documents/dropbox/gss project/code/')\n",
      "from GSSUtility import articleClass\n",
      "import cPickle as cp\n",
      "\n",
      "# GLOBALS\n",
      "GSS_YEARS = [1972, 1973, 1974, 1975, 1976, 1977, 1978, \n",
      "            1980, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, \n",
      "            1990, 1991, 1993, 1994, 1996, 1998, \n",
      "            2000, 2002, 2004, 2006, 2008, 2010, 2012]\n",
      "pathToData = 'c:/users/misha/dropbox/gss project/Data/'  \n",
      "   \n",
      "# LOAD DATA ###########################\n",
      "VARS_IN_ARTICLE = cp.load(open(pathToData + 'VARS_IN_ARTICLE-9-20-2013.pickle', 'rb')) # load the variables used\n",
      "articleIDAndGSSYearsUsed = cp.load(open(pathToData + 'articleIDAndGssYearsUsed-cleaned.pickle')) # load the years used\n",
      "VARS_BY_YEAR = cp.load(open(pathToData + 'VARS_BY_YEAR.pickle', 'rb')) # key=year, value=set('VAR1', 'VAR2', ...)\n",
      "articleIDAndYearPublished = cp.load(open(pathToData + 'articleIDAndYearPublished.pickle'))\n",
      "\n",
      "# this function is used to impute GSSYearsUsed for articles for which we have variable information but not \n",
      "# GSS_years_used information\n",
      "def impute_GSS_years_used(variables, publication_year):\n",
      "    candidate_years = [yr for yr in GSS_YEARS if yr <= (publication_year-2)]\n",
      "    return [yr for yr in candidate_years if set(IVs + DVs + controls + centralIVs).issubset(VARS_BY_YEAR[yr])]\n",
      "\n",
      "maxyear = 0\n",
      "countOfNoGSSYearsUsed\n",
      "\n",
      "# CONSTRUCT articleCLasses LIST\n",
      "articleClasses = []\n",
      "for articleID in VARS_IN_ARTICLE: # for each article for which we have information on its variables...\n",
      "    \t\n",
      "    # check if the central variable in the article is from GSS and skip if it's not\n",
      "    # (GSS_C..V.. is a dict where {article : Bool})\n",
      "    # 2 conditions in IF statement because need to make sure we have a record for this\n",
      "    # article first, and then see what the record says\n",
      "    # I AM GOING TO IGNORE THIS FILTER FOR NOW  \n",
      "    # if articleID not in GSS_CENTRAL_VARIABLE or not GSS_CENTRAL_VARIABLE[articleID]:continue\n",
      "    \n",
      "    # get all variable types for the article \n",
      "    IVs =  map(str.upper, VARS_IN_ARTICLE[articleID]['ivs'])\n",
      "    DVs =  map(str.upper,VARS_IN_ARTICLE[articleID]['dvs'])\n",
      "    controls =  map(str.upper,VARS_IN_ARTICLE[articleID]['controls'])\n",
      "    centralIVs = map(str.upper,VARS_IN_ARTICLE[articleID]['centralIVs'])\n",
      "\n",
      "    # some of the entries in the dictionary below are bunk (=0).. where to do the \n",
      "    # check for the quality of these? I'll just do it here, I guess\n",
      "    yearPublished = articleIDAndYearPublished[articleID]\n",
      "    if yearPublished < 1972 or yearPublished > 2014: yearPublished=None\n",
      "\n",
      "    # skip articles for whcih we do not have information on GSS years used\n",
      "    try: oldGSSYears = articleIDAndGSSYearsUsed[articleID]\n",
      "    except: \n",
      "        if yearPublished is None:\n",
      "            countOfNoGSSYearsUsed+=1\n",
      "        else:\n",
      "            # impute GSS years\n",
      "            oldGSSYears = impute_GSS_years_used(set(IVs + DVs + controls + centralIVs), yearPublished)\n",
      "\n",
      "    # check to make SURE that the GSS years the article allegedly used contain all the VARIABLES\n",
      "    # the article allegedly used\n",
      "    oldGSSYears = [yr for yr in oldGSSYears if set(IVs + DVs + controls + centralIVs).issubset(VARS_BY_YEAR[yr])]   \n",
      "\n",
      "    unusedGSSYears = set(GSS_YEARS) - set(oldGSSYears) # whether the variables are in that year or not..\n",
      "    newGSSYears = [yr for yr in sorted(unusedGSSYears) if set(IVs + DVs + controls + centralIVs).issubset(VARS_BY_YEAR[yr])]  \n",
      "\n",
      "    # some of the entries in the dictionary below are bunk (=0).. where to do the \n",
      "    # check for the quality of these? I'll just do it here, I guess\n",
      "    yearPublished = articleIDAndYearPublished[articleID]\n",
      "    if yearPublished < 1972 or yearPublished > 2014: yearPublished=None\n",
      "    \n",
      "    if yearPublished > maxyear:\n",
      "        maxyear = yearPublished\n",
      "\n",
      "    currentArticle = articleClass(articleID, IVs, DVs, controls, centralIVs, oldGSSYears, newGSSYears, yearPublished=yearPublished)\n",
      "    articleClasses.append(currentArticle)\n",
      "\n",
      "    \n",
      "# save the list    \n",
      "# cp.dump(articleClasses, open(pathToData + 'articleClasses.pickle', 'wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}